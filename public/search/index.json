[{"content":"🎯 Objective Transfer data from a source GCP project to a destination project, including Cloud Storage buckets, Firestore (Datastore), and BigQuery datasets.\nCreate in Terraform:\nBuckets BQ Datasets Datastore db 🛠️ Pre-Requisites Access to both source and destination GCP projects. Gsuite alias account for managing the data transfer securely. The scripts you will need - GCP-data-transfer-between-projects-GitHub-repo 📋 Instructions Create a GSuite Alias Account Set up a GSuite alias account that will be used solely for this data transfer. Ensure the account has minimum required privileges (e.g., access to only relevant buckets, Firestore, and BigQuery). Grant Access in Destination Project Grant the required permissions in the Google Cloud Console under the specific Dev folder or relevant folder in the Destination Project. Ensure this account has sufficient privileges in the Destination Project. Log into GCP with the Test Account Use the alias account to log into Google Cloud Platform (GCP). Validate access by navigating to the destination project. Revoke Excess Access To prevent any unintentional access, revoke any excess permissions in your terminal: This ensures that only the intended project is accessed during the transfer. 1 2 3 4 gcloud auth revoke gcloud auth login gcloud projects list gcloud config get project Delete Storage Buckets in the Destination Project Navigate to Cloud Storage in the Destination Project and delete any existing buckets that need to be recreated or refreshed. Delete the Firestore Database in the Destination Project Go to Firestore in the Destination Project and delete the database if required. Ensure that you are aware of the data that needs to be replaced. Export Firestore Database from Source Project In the Source Project, export the Firestore database to a Cloud Storage bucket. Create Storage Buckets in the Destination Project - Terraform Use Terraform to create the necessary Cloud Storage buckets in the Destination Project. Ensure that bucket configurations match the source project for consistency. Create BigQuery Datasets in the Destination Project - Terraform Use Terraform to set up the BigQuery datasets in the Destination Project. Ensure that dataset schemas and settings match the source. Create Firestore (Datastore) in the Destination Project - Terraform Again, using Terraform, create the necessary Firestore in Datastore mode (default) database in the Destination Project. Locate Bootstrap Scripts Find the bootstrap scripts in my GitHub repository here. These scripts will automate the seeding of data into the destination project. Synchronize Cloud Storage Data Run the script seed-gcs.sh, which synchronizes data between Cloud Storage buckets from the source to the destination project. This step ensures that all files from the source bucket are transferred to the destination bucket. 1 ./seed-gcs.sh [SOURCE] [DESTINATION] Synchronize Firestore (Datastore) Data Use the seed-datastore.sh script to synchronize the exported Datastore content from the source bucket to the destination bucket. This script also imports data into the Firestore (Datastore) in the Destination Project. Key environment variables to set: SRC_LOCATION: Source project location. SRC_BUCKET: Name of the source bucket. SNAPSHOT: Snapshot of the data. DEST_PROJECT: Destination project name. 1 ./seed-datastore.sh [DESTINATION] Create Composite Indexes in Datastore (Destination) Define indexes in an index.yaml file based on query requirements. Use gcloud to create the indexes: 1 gcloud firestore indexes create index.yaml Synchronize BigQuery Data Run the seed-bigquery.sh script to synchronize BigQuery data from the source to the destination project. 1 ./seed-bigquery.sh [SOURCE] [DESTINATION] Update Service Config in Datastore In Firestore (Datastore), update the Service Config for the application: Namespace: [] Kind: [] Update the hostname to point to the correct VM within the destination project. Bounce the Pods and VMs After all data is transferred and services are set up, restart the pods and VMs to ensure all services start fresh and use the new data. ","date":"2024-09-30T00:00:00Z","image":"http://localhost:1313/p/%EF%B8%8F-moving-data-between-gcp-projects/buckets/GCP%20buckets_hu6572220632802544024.png","permalink":"http://localhost:1313/p/%EF%B8%8F-moving-data-between-gcp-projects/buckets/","title":"🌥️ Moving data between GCP projects/buckets 🌐"},{"content":"👋 Introduction In my role as a DevOps Engineer, I tackled the challenge of importing our existing Cloudflare configurations into Terraform. Manual migration would have been time-consuming and error-prone. cf-terraforming—a powerful tool that automates this process by generating Terraform resource code and fetching resource IDs directly from Cloudflare.\n⚙️ Installation On macOS, installation is straightforward using Homebrew:\n1 2 brew tap cloudflare/cloudflare brew install cloudflare/cloudflare/cf-terraforming ✅ Prerequisites Before getting started, ensure you have:\nA Cloudflare account with defined resources Cloudflare API key An initialized Terraform directory 🔑 Setting Up Credentials Best practice is to store Cloudflare credentials as environment variables:\n1 2 3 # When using API Key export CLOUDFLARE_EMAIL=\u0026#39;user@example.com\u0026#39; export CLOUDFLARE_API_KEY=\u0026#39;my_cloudflare_api_key\u0026#39; 💻 Key Commands 🛠️ Generating Resources To generate Terraform code for your Cloudflare resources:\n1 2 3 cf-terraforming generate \\ --resource-type \u0026#34;cloudflare_record\u0026#34; \\ --zone \u0026#34;my_zone_id\u0026#34; \u0026gt;\u0026gt; generated_resources.tf ⬇️ Importing Resources To get import commands and resource IDs:\n1 2 3 cf-terraforming import \\ --resource-type \u0026#34;cloudflare_record\u0026#34; \\ --zone \u0026#34;my_zone_id\u0026#34; 🤔 Difficulties That I Faced While using cf-terraforming, I encountered several challenges:\nResource Naming: The tool assigned resource IDs as names, leading to less readable Terraform code. Import Limitations: Some resources were not supported by cf-terraforming, requiring manual handling. To overcome these issues, I:\nRenamed Resources: Updated the resource names in the Terraform files for clarity. Custom Script for Resource IDs: Created a script to retrieve resource IDs and integrate them into the Terraform import commands. 💡 Pro Tips Resource Naming: cf-terraforming names resources based on IDs. Consider renaming them for better readability. Version Control: Always commit your generated Terraform code to version control. Validation: After importing, use terraform plan to verify the imported state matches the actual configuration. 🛠️ Available Commands The tool offers several useful commands:\ngenerate: Create Terraform resource definitions import: Generate import commands version: Check tool version help: Access detailed help 🎉 Conclusion cf-terraforming significantly streamlines the process of managing Cloudflare resources with Terraform. While it may require some post-processing for resource naming, it\u0026rsquo;s an invaluable tool for DevOps automation.\n","date":"2024-08-21T00:00:00Z","image":"http://localhost:1313/p/cf-terraforming-the-tool-to-import-cloudflare-configurations-into-terraform/terraform-cloudflare_hu3060946697297058844.png","permalink":"http://localhost:1313/p/cf-terraforming-the-tool-to-import-cloudflare-configurations-into-terraform/","title":"🚀 `cf-terraforming` - the tool to Import Cloudflare configurations into Terraform"},{"content":" Prerequisites 🔧 4. Steps: 🚀 4.1. Step 1: Set up the GCP project 4.2. Step 2: Python Flask Microservice 🐍 4.3. Step 3: Dockerfile and the docker image 🐳 4.4. Step 4: Kubernetes manifest files 📄 4.5. Step 5: Cloud SQL Auth Proxy 🔒 4.6. Step 6: Testing and troubleshooting 🧪 Prerequisites 🔧 Cloud Resources:\nGoogle Cloud Platform account and project Service accounts with required permissions gcloud CLI and SDK installed Enabled APIs: Cloud SQL Admin API, Kubernetes Engine API, Artifact Registry API, IAM Service Account Credentials API Cloud SQL instance, database, and user Artifact Registry for storing the Docker image Google Kubernetes Engine cluster Cloud SQL Auth Proxy for connecting to the Cloud SQL instance from the GKE cluster Development Environment:\nCode editor: VS Code (optional) Terraform for provisioning infrastructure Python (for building the Flask microservice) Docker for containerization Kubernetes Tools:\nkubectl for interacting with the Kubernetes cluster 4. Steps: 🚀 4.1. Step 1: Set up the GCP project Create a new project in GCP\nCreate a service account with the required permissions (e.g. Storage Admin, Kubernetes Engine Admin, Artifact Registry Admin, Service Account User)\nAdd a key to the service account and download the JSON file Enable the necessary APIs: Cloud SQL Admin API, Kubernetes Engine API, Artifact Registry API, IAM Service Account Credentials API\nCreate the Terraform files: provider.tf - GCP provider configuration variables.tf - Input variables for the Terraform configuration main.tf - Terraform configuration for creating the Cloud SQL instance, database, and user terraform.tfvars - Variable values for the Terraform configuration NOTE: Make sure to include sensitive information in your gitignore file and do not expose them in the main code or in GitHub.\nCreate a Google Kubernetes Engine cluster\nmain.tf - Terraform configuration for creating the GKE cluster Create an Artifact Registry repository in GCP and push the Docker image to the registry.\nmain.tf - Terraform configuration for creating the Artifact Registry repository Run gcloud auth activate-service-account --key-file=[KEY_FILE] to authenticate the service account\nRun terraform init to initialize the Terraform configuration\nRun terraform plan to view the resources that will be created\nRun terraform apply to create the resources\n4.2. Step 2: Python Flask Microservice 🐍 Build a simple Python Flask microservice (using Terraform) that retrieves the current date/time from a Cloud SQL database\nsample-app.py: Python Flask code for the microservice requirements.txt: Required Python packages (e.g. Flask, Flask-SQLAlchemy, MySQL-connecttor-python) 4.3. Step 3: Dockerfile and the docker image 🐳 - **Dockerfile:** Configuration for building the Docker image Run gcloud auth configure-docker to authenticate Docker to the Artifact Registry Run docker build -t [HOSTNAME]/[PROJECT-ID]/[REPOSITORY]/[IMAGE]:[TAG] . to build and tag the Docker image Run docker push [HOSTNAME]/[PROJECT-ID]/[REPOSITORY]/[IMAGE]:[TAG] to push the Docker image to the Artifact Registry 4.4. Step 4: Kubernetes manifest files 📄 Create the Kubernetes manifest files for the deployment, service, and Kubernetes service account (KSA)\nkubernetes-deployment-manifest.yaml: Deployment configuration for the microservice kubernetes-loadbalancer.yaml: Service configuration for exposing the microservice kubernetes-service-account.yaml: Kubernetes service account configuration for the microservice Run gcloud container clusters get-credentials [CLUSTER_NAME] --zone [ZONE] --project [PROJECT_ID] to authenticate kubectl to the GKE cluster\nRun kubectl apply -f kubernetes-deployment-manifest.yaml to deploy the microservice\nRun kubectl apply -f kubernetes-loadbalancer.yaml to expose the microservice (I use LoadBalancer)\nRun kubectl apply -f kubernetes-service-account.yaml to create the Kubernetes service account\nKubernetes secrets(to store the Cloud SQL credentials):\nmain.tf: Terraform configuration for creating the Kubernetes secret 4.5. Step 5: Cloud SQL Auth Proxy 🔒 The Cloud SQL Auth Proxy is a Cloud SQL connector that provides secure access to your instances without a need for Authorized networks or for configuring SSL. When you connect using the Cloud SQL Auth Proxy, the Cloud SQL Auth Proxy is added to your pod using the sidecar container pattern. The Cloud SQL Auth Proxy container is in the same pod as your application, which enables the application to connect to the Cloud SQL Auth Proxy using localhost, increasing security and performance. I used the method Workload Identity to bind a KSA to a GSA, causing any deployments with that KSA to authenticate as the GSA in their interactions with Google Cloud. GKE Autopilot cluster has Workload Identity enabled by default.\nCreate a Google service account (GSA) with the required permissions (e.g. Cloud SQL Client) Bind the KSA to the GSA by this command: 1 2 3 4 gcloud iam service-accounts add-iam-policy-binding \\ --role roles/iam.workloadIdentityUser \\ --member \u0026#34;serviceAccount:[PROJECT_ID].svc.id.goog[NAMESPACE]/[KSA_NAME]\u0026#34; \\ [GSA_EMAIL] 4.6. Step 6: Testing and troubleshooting 🧪 Test the Kubernetes deployment and the pods by running kubectl get deployments and kubectl get pods. Test the microservice by sending a GET request to the load balancer IP address curl \u0026lt;EXTERNAL IP ADDRESS\u0026gt; \u0026lt;http://EXTERNAL IP ADDRESS\u0026gt; GET http://EXTERNAL IP ADDRESS ","date":"2024-05-03T00:00:00Z","image":"http://localhost:1313/p/kubernetes-sampleapp-microservice-deployment-on-gcp-with-terraform/architecture-diagram_hu5752894124558691497.png","permalink":"http://localhost:1313/p/kubernetes-sampleapp-microservice-deployment-on-gcp-with-terraform/","title":"Kubernetes `SampleApp` Microservice Deployment on GCP with Terraform 🚀"},{"content":"Reference website: https://www.cloudresumeapi.dev\nPre-requisites 🔧\nA Google Cloud Platform account and a project The Terraform CLI The text editor I used is Visual Studio Code 1. 🌀 To get started, I set up your GCP and GitHub A project and service account in GCP A GitHub repository A Firestore database - set up a table named Resumes containing sample resume data 2. 📝 Create a JSON Resume Use this schema to create your own JSON resume.\n3. 📂 Clone the project repository to your local machine and change directory to the project directory Create the infrastructure using Terraform 🛠️\nprovider.tf variables.tf terraform.tfvars main.tf 4. 🐍 Create the function using Python Google Cloud Functions 🌀: Fetch and return resume data based on an id. Utilize HTTP Trigger with anonymous access.\nmain.py requirements.txt (define the dependencies - these will be installed when the function is deployed) In the main.py you have to import Flask - used for web development, including the jsonify method used in the script and google-cloud-firestore - used to interact with Firestore\nfunctions-framework=3.* - The functions-framework is a set of libraries for writing lightweight, portable Python functions that can run in various environments, including Google Cloud Functions, your local development machine, or other cloud environments. It provides a consistent execution environment and request context, and allows you to focus on writing your function logic rather than worrying about the infrastructure.\n5. 🏗️ Initialize the Terraform project Once you have configured the project, you can upload the Terraform configuration to Google Cloud Platform by running the following command:\n1 terraform plan To check the changes that will be made to your infrastructure.\n1 terraform apply When prompted, review the changes and type yes to confirm that you want to apply the changes.\n6. Create the Cloud Build for CI/CD :building_construction: I authorized Cloud Build to access the GitHub repository I created a trigger to build the function when a new commit is pushed to the repository I created the cloudbuild.yaml file to define the build steps 7. 🧪 Test the API API URL: https://europe-west2-cloud-resume-api-418008.cloudfunctions.net/cloudresumeapi-1\nOr open the terminal and run the following command:\n1 curl https://europe-west2-cloud-resume-api-418008.cloudfunctions.net/cloudresumeapi-1 ","date":"2024-03-23T00:00:00Z","image":"http://localhost:1313/p/%EF%B8%8F-gcp-cloud-resume-api-challenge/architecture-image_hu10774068868920502657.png","permalink":"http://localhost:1313/p/%EF%B8%8F-gcp-cloud-resume-api-challenge/","title":"🌥️ **GCP Cloud Resume API Challenge** 🌐"},{"content":"Architecture 🏗 Hey!👋 I am Dominik and this project is a Terraform configuration that creates a static website on Google Cloud Platform.☁ The website is my personal portfolio and is hosted on a Cloud Storage bucket. The website is served using an HTTPS load balancer, which provides SSL termination. This ensures that all traffic to the website is secure and encrypted. The website is accessible at www.domssocial.co.uk.\nThe project also creates a DNS zone for the website, which is used to route traffic to the load balancer. And the Cloud CDN is used to cache the website content and improve performance.\nNOTE: This website is currently not accessible as the infrastructure has been scaled down to minimize costs.\n❔Why did I do this? I wanted to create a simple, cost-effective way to host a static website on Google Cloud Platform. I also wanted to learn how to use Terraform to create infrastructure on GCP.\n🤷‍♂️So what is a static website? A static website is a website that is made up of HTML, CSS, and JavaScript files. These files are served directly to the user\u0026rsquo;s web browser, without any server-side processing. This makes static websites fast and cost-effective to host.\n☝Pre-requisites:\nA Google Cloud Platform account and a project The Terraform CLI A text editor like Visual Studio Code 1.🌀To get started, clone the project repository to your local machine and change directory to the project directory 1 git clone https://github.com/dom-j/GCP-static-website.git 1 cd GCP-static-website 2. Set up your Google Cloud Platform (GCP) Before you start configuring the project, you will need to set up your GCP account and create a project.\nCreate a Google Cloud Platform (GCP) account Create a new project Create a service account for the project DNS zone for the project You will also need to register a domain name and configure it to use Google Cloud DNS - I used https://domains.squarespace.com/ to register my domain, however you can use any domain registrar. In GCP you will need to enable some API services like IAM Service Account Credentials API, Cloud DNS API\u0026hellip;etc 3. Initialize the Terraform project 1 terraform init 4.Configuring the Project💻 I created 3 Terraform .tf files to configure the project:\nmain.tf - This file contains the main configuration for the project, including the Cloud Storage bucket, the IAM policy binding, the HTTP load balancer, and the Cloud CDN. variables.tf - This file contains the input variables for the project, including the project ID, the bucket name, and the index page. provider.tf - This file contains the provider configuration for Google Cloud Platform. 5. Download and add your JSON key file to the project The service account key file is used to authenticate Terraform to your GCP account. You can create a service account and download the key file by following the instructions in the GCP documentation.\n6. Creating the Static Website Once you have configured the project, you can upload the Terraform configuration to Google Cloud Platform by running the following command:\n1 terraform plan To check the changes that will be made to your infrastructure.\n1 terraform apply When prompted, review the changes and type yes to confirm that you want to apply the changes.\nTerraform will then create the following resources:\nA Cloud Storage bucket An IAM policy binding that grants the storage.objectViewer role to the allUsers group Cloud CDN for the bucket SSL certificate for the domain An HTTPS load balancer 7. Testing the Static Website👏 Once the static website has been created, you can test it by visiting the following URL: \u0026lt;www.domssocial.co.uk\u0026gt;\nHow it works🧮 When a user visits the website, the following steps occur:\nCloud DNS: The user enters your domain name in their browser. Cloud DNS translates the domain name to the IP address of the Cloud CDN edge location closest to the user. Cloud CDN Caching: The user\u0026rsquo;s browser connects to the nearest Cloud CDN edge location. Cloud CDN checks its cache for the requested content (static files like images, HTML, CSS, JavaScript). Cache Hit: If the content is already cached at the edge location, Cloud CDN serves the content directly to the user\u0026rsquo;s browser, resulting in faster delivery due to reduced latency. Load Balancer: If Cloud CDN doesn\u0026rsquo;t have the requested content cached, it forwards the request to the Load Balancer. Backends: The Load Balancer distributes the request traffic across your backends, which are the Cloud Storage buckets that host your website content. The Frontend design of the website The frontend of the website is a HTML, CSS and JS files. I downloaded the template from https://html5up.net/, and modified it to suit my needs.\nSkills gained📚 How to use Terraform to create infrastructure on Google Cloud Platform How to create a static website on Google Cloud Platform How to use Cloud Storage, Cloud CDN, and an HTTPS load balancer to host a static website How to use and create Cloud DNS zones How to use a service account key file to authenticate Terraform to Google Cloud Platform How to create an SSL certificate for a domain Gained some experience with HTML, CSS and JS ","date":"2024-02-17T00:00:00Z","image":"http://localhost:1313/p/my-first-static-website-on-google-cloud-platform-%EF%B8%8F-using-terraform/GCP-static-website-plan-Terraform_hu5932024895085465543.png","permalink":"http://localhost:1313/p/my-first-static-website-on-google-cloud-platform-%EF%B8%8F-using-terraform/","title":"My first static website 🌐 on Google Cloud Platform ☁️ using Terraform 🔨"},{"content":"正文测试 而这些并不是完全重要，更加重要的问题是， 带着这些问题，我们来审视一下学生会退会。 既然如何， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 我们不得不面对一个非常尴尬的事实，那就是， 可是，即使是这样，学生会退会的出现仍然代表了一定的意义。 学生会退会，发生了会如何，不发生又会如何。 经过上述讨论， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 学生会退会，到底应该如何实现。 这样看来， 在这种困难的抉择下，本人思来想去，寝食难安。 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 就我个人来说，学生会退会对我的意义，不能不说非常重大。 莎士比亚曾经提到过，人的一生是短的，但如果卑劣地过这一生，就太长了。这似乎解答了我的疑惑。 莫扎特说过一句富有哲理的话，谁和我一样用功，谁就会和我一样成功。这启发了我， 对我个人而言，学生会退会不仅仅是一个重大的事件，还可能会改变我的人生。 学生会退会，到底应该如何实现。 一般来说， 从这个角度来看， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 在这种困难的抉择下，本人思来想去，寝食难安。 了解清楚学生会退会到底是一种怎么样的存在，是解决一切问题的关键。 一般来说， 生活中，若学生会退会出现了，我们就不得不考虑它出现了的事实。 问题的关键究竟为何？ 而这些并不是完全重要，更加重要的问题是。\n奥斯特洛夫斯基曾经说过，共同的事业，共同的斗争，可以使人们产生忍受一切的力量。　带着这句话，我们还要更加慎重的审视这个问题： 一般来讲，我们都必须务必慎重的考虑考虑。 既然如此， 这种事实对本人来说意义重大，相信对这个世界也是有一定意义的。 带着这些问题，我们来审视一下学生会退会。 我认为， 我认为， 在这种困难的抉择下，本人思来想去，寝食难安。 问题的关键究竟为何？ 每个人都不得不面对这些问题。 在面对这种问题时， 要想清楚，学生会退会，到底是一种怎么样的存在。 我认为， 既然如此， 每个人都不得不面对这些问题。 在面对这种问题时， 那么， 我认为， 学生会退会因何而发生。\n引用 思念是最暖的忧伤像一双翅膀\n让我停不了飞不远在过往游荡\n不告而别的你 就算为了我着想\n这么沉痛的呵护 我怎么能翱翔\n最暖的憂傷 - 田馥甄\n图片 1 2 3 ![Photo by Florian Klauer on Unsplash](florian-klauer-nptLmg6jqDo-unsplash.jpg) ![Photo by Luca Bravo on Unsplash](luca-bravo-alS7ewQ41M8-unsplash.jpg) ![Photo by Helena Hertz on Unsplash](helena-hertz-wWZzXlDpMog-unsplash.jpg) ![Photo by Hudai Gayiran on Unsplash](hudai-gayiran-3Od_VKcDEAA-unsplash.jpg) 相册语法来自 Typlog\n","date":"2020-09-09T00:00:00Z","image":"http://localhost:1313/helena-hertz-wWZzXlDpMog-unsplash.jpg","permalink":"http://localhost:1313/p/test-chinese/","title":"Chinese Test"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL + ALT + Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2019-03-11T00:00:00Z","image":"http://localhost:1313/p/markdown-syntax-guide/pawel-czerwinski-8uZPynIu-rQ-unsplash_hu6307248181568134095.jpg","permalink":"http://localhost:1313/p/markdown-syntax-guide/","title":"Markdown Syntax Guide"},{"content":"Lorem est tota propiore conpellat pectoribus de pectora summo.\nRedit teque digerit hominumque toris verebor lumina non cervice subde tollit usus habet Arctonque, furores quas nec ferunt. Quoque montibus nunc caluere tempus inhospita parcite confusaque translucet patri vestro qui optatis lumine cognoscere flos nubis! Fronde ipsamque patulos Dryopen deorum.\nExierant elisi ambit vivere dedere Duce pollice Eris modo Spargitque ferrea quos palude Rursus nulli murmur; hastile inridet ut ab gravi sententia! Nomine potitus silentia flumen, sustinet placuit petis in dilapsa erat sunt. Atria tractus malis.\nComas hunc haec pietate fetum procerum dixit Post torum vates letum Tiresia Flumen querellas Arcanaque montibus omnes Quidem et Vagus elidunt The Van de Graaf Canon\nMane refeci capiebant unda mulcebat Victa caducifer, malo vulnere contra dicere aurato, ludit regale, voca! Retorsit colit est profanae esse virescere furit nec; iaculi matertera et visa est, viribus. Divesque creatis, tecta novat collumque vulnus est, parvas. Faces illo pepulere tempus adest. Tendit flamma, ab opes virum sustinet, sidus sequendo urbis.\nIubar proles corpore raptos vero auctor imperium; sed et huic: manus caeli Lelegas tu lux. Verbis obstitit intus oblectamina fixis linguisque ausus sperare Echionides cornuaque tenent clausit possit. Omnia putatur. Praeteritae refert ausus; ferebant e primus lora nutat, vici quae mea ipse. Et iter nil spectatae vulnus haerentia iuste et exercebat, sui et.\nEurytus Hector, materna ipsumque ut Politen, nec, nate, ignari, vernum cohaesit sequitur. Vel mitis temploque vocatus, inque alis, oculos nomen non silvis corpore coniunx ne displicet illa. Crescunt non unus, vidit visa quantum inmiti flumina mortis facto sic: undique a alios vincula sunt iactata abdita! Suspenderat ego fuit tendit: luna, ante urbem Propoetides parte.\n","date":"2019-03-09T00:00:00Z","image":"http://localhost:1313/p/placeholder-text/matt-le-SJSpo9hQf7s-unsplash_hu10664154974910995856.jpg","permalink":"http://localhost:1313/p/placeholder-text/","title":"Placeholder Text"},{"content":"Mathematical notation in a Hugo project can be enabled by using third party JavaScript libraries.\nIn this example we will be using KaTeX\nCreate a partial under /layouts/partials/math.html Within this partial reference the Auto-render Extension or host these scripts locally. Include the partial in your templates like so: 1 2 3 {{ if or .Params.math .Site.Params.math }} {{ partial \u0026#34;math.html\u0026#34; . }} {{ end }} To enable KaTeX globally set the parameter math to true in a project\u0026rsquo;s configuration To enable KaTeX on a per page basis include the parameter math: true in content files Note: Use the online reference of Supported TeX Functions\nExamples Inline math: $\\varphi = \\dfrac{1+\\sqrt5}{2}= 1.6180339887…$\nBlock math: $$ \\varphi = 1+\\frac{1} {1+\\frac{1} {1+\\frac{1} {1+\\cdots} } } $$","date":"2019-03-08T00:00:00Z","permalink":"http://localhost:1313/p/math-typesetting/","title":"Math Typesetting"},{"content":"Emoji can be enabled in a Hugo project in a number of ways.\nThe emojify function can be called directly in templates or Inline Shortcodes.\nTo enable emoji globally, set enableEmoji to true in your site\u0026rsquo;s configuration and then you can type emoji shorthand codes directly in content files; e.g.\n🙈 :see_no_evil: 🙉 :hear_no_evil: 🙊 :speak_no_evil:\nThe Emoji cheat sheet is a useful reference for emoji shorthand codes.\nN.B. The above steps enable Unicode Standard emoji characters and sequences in Hugo, however the rendering of these glyphs depends on the browser and the platform. To style the emoji you can either use a third party emoji font or a font stack; e.g.\n1 2 3 .emoji { font-family: Apple Color Emoji, Segoe UI Emoji, NotoColorEmoji, Segoe UI Symbol, Android Emoji, EmojiSymbols; } ","date":"2019-03-05T00:00:00Z","image":"http://localhost:1313/p/emoji-support/the-creative-exchange-d2zvqp3fpro-unsplash_hu5876398126655421130.jpg","permalink":"http://localhost:1313/p/emoji-support/","title":"Emoji Support"}]